{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Neural Creative Transfer\n",
    "\n",
    "We implement an modification of Gatys, Ecker and Bethge's [neural style transfer algorithm](http://arxiv.org/abs/1508.06576) for our creative assets.\n",
    "\n",
    "The algorith uses a VGG-19 network to separate and recombine content of an creative and style of a website, and therefore provides a system for creating native creative for advertising. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import scipy.misc\n",
    "import tensorflow as tf \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def setup_model_from_file(path, image_height, image_width, color_channels):\n",
    "    \"\"\"\n",
    "    We start with the pre-trained VGG model from the paper \"Very Deep Convolutional Networks for Large-Scale \n",
    "    Visual Recognition\". We  strip out all the conv, relu and pool layers from the VGG-19 network and replace\n",
    "    the maxpool layers with average pool layers as suggested by the authors in the \"A Neural Algorithm of \n",
    "    Artistic Style\" paper. Here are the configuration for our modified VGG network (layer, filter height,\n",
    "    filter width, input channels, output channels):\n",
    "        conv1_1  :  3  3  3    64\n",
    "        conv1_2  :  3  3  64   64 \n",
    "        avgpool  :\n",
    "        conv2_1  :  3  3  64   128  \n",
    "        conv2_2  :  3  3  128  128 \n",
    "        avgpool  :\n",
    "        conv3_1  :  3  3  128  256 \n",
    "        conv3_2  :  3  3  256  256\n",
    "        conv3_3  :  3  3  256  256\n",
    "        conv3_4  :  3  3  256  256\n",
    "        avgpool  :\n",
    "        conv4_1  :  3  3  256  512  \n",
    "        conv4_2  :  3  3  512  512\n",
    "        conv4_3  :  3  3  512  512\n",
    "        conv4_4  :  3  3  512  512\n",
    "        avgpool  :\n",
    "        conv5_1  :  3  3  512  512 \n",
    "        conv5_2  :  3  3  512  512 \n",
    "        conv5_3  :  3  3  512  512 \n",
    "        conv5_4  :  3  3  512  512 \n",
    "        avgpool  :    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Strip out the layers from the VGG-19 model \n",
    "    vgg = scipy.io.loadmat(path)['layers'] \n",
    "    \n",
    "    def _weights(layer):\n",
    "        \"\"\"\n",
    "        Extract the weights and bias at a given layer.\n",
    "        \"\"\"\n",
    "        W = vgg[0][layer][0][0][2][0][0]\n",
    "        b = vgg[0][layer][0][0][2][0][1]\n",
    "        return W, b\n",
    "\n",
    "    def _conv2d(prev_layer, layer):\n",
    "        \"\"\"\n",
    "        Construct the conv2d layer from the VGG model.\n",
    "        \"\"\"\n",
    "        W, b = _weights(layer)\n",
    "        W = tf.constant(W)\n",
    "        b = tf.constant(np.reshape(b, (b.size)))\n",
    "        return tf.nn.conv2d(prev_layer, filter=W, strides=[1, 1, 1, 1], padding='SAME') + b\n",
    "\n",
    "    def _avg_pool(prev_layer):\n",
    "        \"\"\"\n",
    "        Return the average pooling layer.\n",
    "        \"\"\"\n",
    "        return tf.nn.avg_pool(prev_layer, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "    # Set up the modifiled VGG network.  \n",
    "    network = {}\n",
    "    network['input']    = tf.Variable(np.zeros((1, image_height, image_width, color_channels)), dtype = 'float32')\n",
    "    network['conv1_1']  = tf.nn.relu(_conv2d(network['input'], 0))\n",
    "    network['conv1_2']  = tf.nn.relu(_conv2d(network['conv1_1'], 2))    \n",
    "    network['avgpool1'] = _avgpool(network['conv1_2'])\n",
    "    network['conv2_1']  = tf.nn.relu(_conv2d(network['avgpool1'], 5))\n",
    "    network['conv2_2']  = tf.nn.relu(_conv2d(network['conv2_1'], 7))\n",
    "    network['avgpool2'] = _avgpool(network['conv2_2'])\n",
    "    network['conv3_1']  = tf.nn.relu(_conv2d(network['avgpool2'], 10))\n",
    "    network['conv3_2']  = tf.nn.relu(_conv2d(network['conv3_1'], 12))\n",
    "    network['conv3_3']  = tf.nn.relu(_conv2d(network['conv3_2'], 14))\n",
    "    network['conv3_4']  = tf.nn.relu(_conv2d(network['conv3_3'], 16))\n",
    "    network['avgpool3'] = _avgpool(network['conv3_4'])\n",
    "    network['conv4_1']  = tf.nn.relu(_conv2d(network['avgpool3'], 19))\n",
    "    network['conv4_2']  = tf.nn.relu(_conv2d(network['conv4_1'], 21))\n",
    "    network['conv4_3']  = tf.nn.relu(_conv2d(network['conv4_2'], 23))\n",
    "    network['conv4_4']  = tf.nn.relu(_conv2d(network['conv4_3'], 25))\n",
    "    network['avgpool4'] = _avgpool(network['conv4_4'])\n",
    "    network['conv5_1']  = tf.nn.relu(_conv2d(network['avgpool4'], 28))\n",
    "    network['conv5_2']  = tf.nn.relu(_conv2d(network['conv5_1'], 30))\n",
    "    network['conv5_3']  = tf.nn.relu(_conv2d(network['conv5_2'], 32))\n",
    "    network['conv5_4']  = tf.nn.relu(_conv2d(network['conv5_3'], 34))\n",
    "    network['avgpool5'] = _avgpool(network['conv5_4'])\n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
